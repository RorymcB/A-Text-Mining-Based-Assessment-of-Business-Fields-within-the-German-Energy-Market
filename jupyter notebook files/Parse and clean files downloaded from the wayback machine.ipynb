{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T18:06:22.013340Z",
     "start_time": "2020-08-24T18:06:21.623198Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T16:51:56.432692Z",
     "start_time": "2020-08-24T16:51:56.426457Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/path/to/html/and/php/files/downloaded/from/waybackmachine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and clean all files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-24T16:53:21.547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt=0\n",
    "websites=[]\n",
    "dfs=[]\n",
    "for folder in os.listdir(path):\n",
    "    \n",
    "    cnt+=1\n",
    "    print('*'*10)\n",
    "    print(cnt,folder,'\\n',datetime.datetime.now())\n",
    "    print('*'*10)\n",
    "    start_count=datetime.datetime.now() ##start timer\n",
    "    \n",
    "    # make a list of all files associated with a particular website\n",
    "    allfiles=[]\n",
    "    for root, dirc, files in os.walk(os.path.join(path,folder)):\n",
    "        for file in files:\n",
    "            allfiles.append(os.path.join(root,file))\n",
    "                \n",
    "    print('Total number of files =', len(allfiles))\n",
    "    \n",
    "    # parse files and clean resulting text data\n",
    "    \n",
    "    keys=[]\n",
    "    values=[]\n",
    "    \n",
    "    for file in allfiles:\n",
    "        \n",
    "        try:\n",
    "            f = open(file, 'rb')\n",
    "        except Exception as e:\n",
    "            print('!!! ERROR !!!')\n",
    "            print(str(e))\n",
    "            continue\n",
    "        document= BeautifulSoup(f.read(),'lxml').get_text(strip=False)\n",
    "        \n",
    "        if len(document) > 0:\n",
    "\n",
    "            keys.append(file.split('/')[-2])\n",
    "            sometxt=document.split(',')    \n",
    "            sometxt=[item.replace('\\n', ' ').replace('\\t',' ').replace('\\xa0',' ') for item in sometxt]\n",
    "            moretxt=[]\n",
    "            for item in sometxt:\n",
    "                moretxt.extend(item.split(' '))\n",
    "            moretxt=[item.strip() for item in moretxt]\n",
    "            words=[item for item in moretxt if 50 > len(item) > 1]\n",
    "            text=u' '.join(words)\n",
    "            \n",
    "            lsst=[]\n",
    "            lst= re.findall(r'\\b[^\\d\\W]+', str(text))\n",
    "            lst = [x.lower() for x in lst]\n",
    "            lst = [x.replace('ä','ae').replace('ö','oe').replace('ü','ue').replace('ß','ss') for x in lst]\n",
    "            lsst.extend(lst)\n",
    "            text=u' '.join(lsst)\n",
    "\n",
    "            values.append(text)\n",
    "            \n",
    "    end_count=datetime.datetime.now()     ## stop timer\n",
    "    tt=end_count-start_count              ## calculate time taken\n",
    "    print('Time taken was %s \\n' % tt)\n",
    "    \n",
    "    # create a default dictionary where the keys are the months corresponding to the snapshots and \n",
    "    # the values are the text from the snapshots\n",
    "    \n",
    "    defdict = defaultdict(list)\n",
    "    for i, j in zip(keys, values):\n",
    "        defdict[i].append(j)\n",
    "        \n",
    "    # create a dataframe from a regular dictionary where the values from each key of the default dictionary\n",
    "    # are joined together as one string but seperated by !!!!.\n",
    "    # Then store this dataframe in a list of dataframes\n",
    "    \n",
    "    new_keys=[]\n",
    "    new_values=[]\n",
    "    for key in defdict:\n",
    "        new_keys.append(key)\n",
    "        new_values.append('!!!!'.join([item for item in defdict.get(key)]))\n",
    "        dictionary = dict(zip(new_keys, new_values))\n",
    "    \n",
    "    df=pd.DataFrame(dictionary,index=[cnt])\n",
    "    \n",
    "    websites.append(folder)\n",
    "    dfs.append(df)\n",
    "    \n",
    "    # when the list contains 10 dataframes join them together as 1 dataframe \n",
    "    # and export the new dataframe to a pickle file\n",
    "    \n",
    "    if cnt%10 == 0:\n",
    "        \n",
    "        df_words=pd.concat(dfs, keys = websites, names = ['Website', 'Index'], sort=True)\n",
    "        outputpath='/path/to/output/folder/parsing_results_%s.p' % str(cnt/10)\n",
    "        with open(outputpath,'wb') as f:\n",
    "            pickle.dump(df_words,f)\n",
    "        print('-§-'*10)\n",
    "        print('Parsing results %s have been exported' % str(cnt/10) )\n",
    "        print('-§-'*10,'\\n')\n",
    "        websites=[]\n",
    "        dfs=[]\n",
    "\n",
    "# join remaining dataframes into 1 dataframe and export to a pickle file\n",
    "        \n",
    "df_words=pd.concat(dfs, keys = websites, names = ['Website', 'Index'], sort=True)\n",
    "outputpath='/path/to/output/folder/parsing_results_%s.p' % str(cnt/10)\n",
    "with open(outputpath,'wb') as f:\n",
    "    pickle.dump(df_words,f)\n",
    "print('-§-'*10)\n",
    "print('Parsing results %s have been exported' % str(cnt/10) )\n",
    "print('-§-'*10,'\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
