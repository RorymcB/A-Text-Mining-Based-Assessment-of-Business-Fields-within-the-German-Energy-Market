{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:44:56.063253Z",
     "start_time": "2020-08-22T14:44:55.891423Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:44:56.152646Z",
     "start_time": "2020-08-22T14:44:56.149138Z"
    }
   },
   "outputs": [],
   "source": [
    "path='/path/to/parsed/text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:44:57.044177Z",
     "start_time": "2020-08-22T14:44:57.041565Z"
    }
   },
   "outputs": [],
   "source": [
    "pathout='/path/to/output/folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T08:34:18.176052Z",
     "start_time": "2021-03-21T08:34:18.170863Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Define functions for removing duplicate texts and creating the document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:44:57.263229Z",
     "start_time": "2020-08-22T14:44:57.258203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(cell):\n",
    "    if pd.notna(cell):\n",
    "        return ' '.join(set(cell.split('!!!!')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## define a function for combining the data stored in accordance with which month it represents\n",
    "## into data representing the year it is from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:44:58.356891Z",
     "start_time": "2020-08-22T14:44:58.347526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def last_10_years(df,years=None):\n",
    "    if years is None:\n",
    "        years=[]\n",
    "        \n",
    "    ## select the data for the years from 2010 up to 2020\n",
    "    for i in range(11):\n",
    "        if i <= 9:\n",
    "            year='201'+str(i)\n",
    "        else:\n",
    "            year='2020'\n",
    "        r=re.compile('^201'+str(i)+'+.*')  ## regex for determining 'from_' and 'to_'\n",
    "        cols=df.index.tolist()\n",
    "        months_in_year=list(filter(r.match,cols)) ## find the months that are represented in each year\n",
    "        \n",
    "        ## isolate and combine the text from each year\n",
    "        if len(months_in_year) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            from_=months_in_year[0]\n",
    "            to_=months_in_year[-1]\n",
    "            years.append(year)\n",
    "        \n",
    "        try:\n",
    "            if len(months_in_year) == 1:\n",
    "\n",
    "                df[year]='!!!!'.join(df[from_:]) ## separate the text with !!!! for later removal of duplicate text\n",
    "            else:\n",
    "\n",
    "                df[year]='!!!!'.join(df[from_:to_])\n",
    "        except:\n",
    "            print('error')\n",
    "    return df[years[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply functions to files containing the parsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:45:00.961694Z",
     "start_time": "2020-08-22T14:45:00.941271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files=os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T14:45:01.632664Z",
     "start_time": "2020-08-22T14:45:01.629471Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T17:30:00.336701Z",
     "start_time": "2020-08-22T17:21:01.056773Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "key_dict=dict()\n",
    "for file in files:\n",
    "    cnt += 1\n",
    "    fname = file.split('_')[-1].split('.')[0]\n",
    "    print('*'*10)\n",
    "    print('ยง',cnt,'ยง',fname, datetime.datetime.now())\n",
    "    print('*'*10, '\\n')\n",
    "    \n",
    "    time_s = datetime.datetime.now()\n",
    "    \n",
    "    ## load the file containing the parsed text from the websites \n",
    "    ## (each file containing approx. data for 10 websites)\n",
    "    fpath = os.path.join(path, file)\n",
    "\n",
    "    with open(fpath, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    df.reset_index('Index', drop=True, inplace=True)\n",
    "    comps=df.index.tolist()\n",
    "    \n",
    "    ## convert data to document matrix where data is arranged according to website and the year that it represents\n",
    "    ## this is performed one website at a time, where the datatype for each website is a pandas Series\n",
    "    ## and each time a new dataframe is created for each website\n",
    "    dfs = []\n",
    "    for ind in df.index:\n",
    "        \n",
    "        dft = df.loc[ind].dropna()\n",
    "        \n",
    "        try:\n",
    "            df_t = last_10_years(dft)\n",
    "            dfs.append(df_t)\n",
    "        except Exception as e:\n",
    "            print('Error: %s' % str(e))\n",
    "            \n",
    "    ## combine the dataframes into one larger dataframe and remove duplicate texts in each cell\n",
    "    df_years = pd.concat(dfs, axis=1, sort=True).T\n",
    "    df_export = df_years.applymap(remove_duplicates)\n",
    "    \n",
    "    ## export document matrix\n",
    "    fout = 'dfy%s.p' % str(cnt)\n",
    "    fpathout = os.path.join(pathout, fout)\n",
    "    with open(fpathout, 'wb') as f:\n",
    "        pickle.dump(df_export, f)\n",
    "    \n",
    "    ## update a dictionary with a record of websites and document matrices\n",
    "    key_dict.update({fout:comps})\n",
    "\n",
    "    time_e = datetime.datetime.now()\n",
    "    tt = time_e-time_s\n",
    "    print('Time taken was %s \\n' % str(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-24T07:39:37.488179Z",
     "start_time": "2020-08-24T07:39:37.482933Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/path/to/store/document/reference/dictionary.p','wb') as f:\n",
    "    pickle.dump(key_dict,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
